import sys
import os
import glob
import json
import pandas as pd
import warnings  # <--- Adicionado
from sqlalchemy import text

# Silencia avisos especÃ­ficos do OpenPyXL sobre validaÃ§Ã£o de dados
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')

# ConfiguraÃ§Ã£o de caminhos
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
if backend_dir not in sys.path:
    sys.path.append(backend_dir)

from db.connection import get_db_engine
from etl.processor import process_dataframe, clean_column_names
from add_indexes import create_indexes
from optimize_db import optimize_database

def load_raw_files():
    raw_path = os.path.join(backend_dir, "raw_data")
    map_path = os.path.join(current_dir, "mapeamento_abas.json")
    
    try:
        with open(map_path, 'r', encoding='utf-8') as f:
            aba_map = json.load(f)
    except FileNotFoundError:
        print("ðŸ”´ Mapeamento (mapeamento_abas.json) nÃ£o encontrado.")
        return []

    all_files = glob.glob(os.path.join(raw_path, "*.xlsx"))
    dfs = []

    print(f"ðŸ“‚ Processando {len(all_files)} arquivos...")

    for file_path in all_files:
        filename = os.path.basename(file_path)
        sheet_name = aba_map.get(filename)
        
        if not sheet_name:
            continue
            
        try:
            # LÃª apenas cabeÃ§alho primeiro
            temp = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
            
            header = temp.iloc[4]
            data = temp.iloc[5:].copy()
            data.columns = clean_column_names(header)
        
            if 'ativo' in data.columns:
                dfs.append(data)
                print(f"  â””â”€â”€ âœ… {filename} (Aba: {sheet_name})")
            else:
                print(f"  â””â”€â”€ âš ï¸ {filename}: Coluna 'ativo' ausente.")
                
        except Exception as e:
            print(f"  â””â”€â”€ ðŸ”´ Erro em {filename}: {e}")

    return dfs

def run():
    print("\nðŸš€ INICIANDO MIGRAÃ‡ÃƒO AUTOMATIZADA")
    print("===================================")
    
    engine = get_db_engine()
    if not engine:
        sys.exit(1)

    # 1. Carregar Dados
    raw_dfs = load_raw_files()
    if not raw_dfs:
        print("âš ï¸ Nenhum dado para processar. Encerrando.")
        sys.exit(0)

    # 2. Processar (ETL)
    print("\nâš™ï¸ Unificando e transformando dados...")
    full_df = pd.concat(raw_dfs, ignore_index=True)
    clean_df = process_dataframe(full_df)
    
    clean_df.reset_index(inplace=True) 
    clean_df.rename(columns={'index': 'id'}, inplace=True)

    total_rows = len(clean_df)
    print(f"ðŸ“Š Dados prontos: {total_rows} registros.")

    # 3. InserÃ§Ã£o no Banco
    print("ðŸ’¾ Inserindo no banco de dados...")
    try:
        with engine.begin() as conn:
            clean_df.to_sql(
                'atividades', 
                conn, 
                if_exists='replace', 
                index=False,
                chunksize=2000 
            )
            
            conn.execute(text("ALTER TABLE atividades ADD PRIMARY KEY (id);"))
            
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS migration_log (
                    id INT PRIMARY KEY, 
                    last_updated_at TIMESTAMP DEFAULT NOW()
                );
                INSERT INTO migration_log (id, last_updated_at) VALUES (1, NOW())
                ON CONFLICT (id) DO UPDATE SET last_updated_at = NOW();
            """))
            
        print("âœ… Dados inseridos com sucesso!")

        # 4. PÃ³s-Processamento
        print("\nðŸ”§ Executando tarefas de manutenÃ§Ã£o pÃ³s-migraÃ§Ã£o...")
        create_indexes()
        optimize_database()

        print("\nâœ¨ MIGRAÃ‡ÃƒO CONCLUÃDA COM SUCESSO! âœ¨")
        
    except Exception as e:
        print(f"\nðŸ”´ FALHA CRÃTICA NA MIGRAÃ‡ÃƒO: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run()